{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08Vub_-gbC5e"
      },
      "outputs": [],
      "source": [
        "!pip install tweepy\n",
        "!pip install tweepy --upgrade\n",
        "!pip install better_profanity\n",
        "import tweepy\n",
        "client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAADRyiwEAAAAAVyAignb%2BpcKAU5rCs%2BAI5Q45Vyk%3DIC8kWmSHu9dkNW8j2PGBs2DpSkMiKmBFkoE7S6WcaprBHhIfil')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "your_query = \"Miami Heat\"\n",
        "query = your_query + ' -is:retweet'\n",
        "\n",
        "tweets = client.search_recent_tweets(query=query, tweet_fields=['context_annotations', 'created_at'], max_results=100)\n",
        "\n",
        "for tweet in tweets.data:\n",
        "    print(tweet.text)\n",
        "    if len(tweet.context_annotations) > 0:\n",
        "        print(tweet.context_annotations)"
      ],
      "metadata": {
        "id": "4pSB0I2figiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your own search query\n",
        "query = 'covid -is:retweet'\n",
        "\n",
        "# Replace the limit=1000 with the maximum number of Tweets you want\n",
        "for tweet in tweepy.Paginator(client.search_recent_tweets, query=query,\n",
        "                              tweet_fields=['context_annotations', 'created_at'], max_results=100).flatten(limit=1000):\n",
        "    print(tweet.id)"
      ],
      "metadata": {
        "id": "Gz1GnssenbDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your own search query\n",
        "query = 'covid -is:retweet'\n",
        "\n",
        "# Name and path of the file where you want the Tweets written to\n",
        "file_name = 'tweets.txt'\n",
        "\n",
        "with open(file_name, 'a+') as filehandle:\n",
        "    for tweet in tweepy.Paginator(client.search_recent_tweets, query=query,\n",
        "                                  tweet_fields=['context_annotations', 'created_at'], max_results=100).flatten(\n",
        "            limit=1000):\n",
        "        filehandle.write('%s\\n' % tweet.id)"
      ],
      "metadata": {
        "id": "7WsvB7h6n0wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'Miami+Heat -is:retweet'\n",
        "\n",
        "tweets = client.search_recent_tweets(query=query, tweet_fields=['context_annotations', 'created_at'],\n",
        "                                     user_fields=['profile_image_url'], expansions='author_id', max_results=100)\n",
        "\n",
        "# Get users list from the includes object\n",
        "users = {u[\"id\"]: u for u in tweets.includes['users']}\n",
        "\n",
        "for tweet in tweets.data:\n",
        "    if users[tweet.author_id]:\n",
        "        user = users[tweet.author_id]\n",
        "        print(user.profile_image_url)"
      ],
      "metadata": {
        "id": "JerLsJq2oII0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install better_profanity"
      ],
      "metadata": {
        "id": "6jna4U558yOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Twitter Sentiment Analysis through Data Mining**"
      ],
      "metadata": {
        "id": "ZkH3cu3hpD74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tweepy \n",
        "\n",
        "from tweepy import OAuthHandler \n",
        "\n",
        "from textblob import TextBlob \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from better_profanity import profanity"
      ],
      "metadata": {
        "id": "kV82QR4HoX_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "your_query = input(\"Please enter your topic / person of interest: \")\n",
        "# your_query = \"Ukraine\"\n",
        "query = your_query + ' -is:retweet'\n",
        "# get tweets from the API\n",
        "tweets = client.search_recent_tweets(query=query,\n",
        "                                     tweet_fields = [\"created_at\", \"text\", \"source\"],\n",
        "                                     user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
        "                                     max_results = 100,\n",
        "                                     expansions='author_id'\n",
        "                                     )\n",
        "print(type(tweets))"
      ],
      "metadata": {
        "id": "075yPhaYpKky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the pandas library\n",
        "import pandas as pd\n",
        "# create a list of records\n",
        "tweet_info_ls = []\n",
        "# iterate over each tweet and corresponding user details\n",
        "for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
        "    tweet_info = {\n",
        "        'created_at': tweet.created_at,\n",
        "        'text': tweet.text,\n",
        "        'source': tweet.source,\n",
        "        'name': user.name,\n",
        "        'username': user.username,\n",
        "        'location': user.location,\n",
        "        'verified': user.verified,\n",
        "        'description': user.description\n",
        "    }\n",
        "    tweet_info_ls.append(tweet_info)\n",
        "# create dataframe from the extracted records\n",
        "tweets_df = pd.DataFrame(tweet_info_ls)\n",
        "# display the dataframe\n",
        "tweets_df.head()"
      ],
      "metadata": {
        "id": "iCo0xyNgqWRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the pandas library\n",
        "import pandas as pd\n",
        "# create a list of records\n",
        "tweet_info_ls = []\n",
        "# iterate over each tweet and corresponding user details\n",
        "for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
        "    tweet_info = {\n",
        "        'text': tweet.text,\n",
        "        'username': user.username,\n",
        "        'location': user.location,\n",
        "    }\n",
        "    tweet_info_ls.append(tweet_info)\n",
        "# create dataframe from the extracted records\n",
        "tweets_df = pd.DataFrame(tweet_info_ls)\n",
        "# display the dataframe\n",
        "tweets_df.tail()"
      ],
      "metadata": {
        "id": "9qUxKNqJrW1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.shape"
      ],
      "metadata": {
        "id": "F5neMyi0rh08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to clean the tweets. Remove profanity, unnecessary characters, spaces, and stopwords.\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    if type(tweet) == np.float:\n",
        "        return \"\"\n",
        "    r = tweet.lower()\n",
        "    r = profanity.censor(r)\n",
        "    r = re.sub(\"'\", \"\", r) # This is to avoid removing contractions in english\n",
        "    r = re.sub(\"@[A-Za-z0-9_]+\",\"\", r)\n",
        "    r = re.sub(\"#[A-Za-z0-9_]+\",\"\", r)\n",
        "    r = re.sub(r'http\\S+', '', r)\n",
        "    r = re.sub('[()!?]', ' ', r)\n",
        "    r = re.sub('\\[.*?\\]',' ', r)\n",
        "    r = re.sub(\"[^a-z0-9]\",\" \", r)\n",
        "    r = r.split()\n",
        "    stopwords = [\"for\", \"on\", \"an\", \"a\", \"of\", \"and\", \"in\", \"the\", \"to\", \"from\"]\n",
        "    r = [w for w in r if not w in stopwords]\n",
        "    r = \" \".join(word for word in r)\n",
        "    return r"
      ],
      "metadata": {
        "id": "jOtv4lx0soKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.iloc[0,0]"
      ],
      "metadata": {
        "id": "beET-OANtBAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df[\"text\"].iloc[21]"
      ],
      "metadata": {
        "id": "dE43TYantQao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_list = tweets_df.text.to_list()"
      ],
      "metadata": {
        "id": "rFoVB-G3tHHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = [clean_tweet(tw) for tw in tweet_list]\n",
        "cleaned"
      ],
      "metadata": {
        "id": "Dg2XzFfDtT6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sentiment objects using TextBlob\n",
        "\n",
        "sentiment_objects = [TextBlob(tweet) for tweet in cleaned]\n",
        "\n",
        "sentiment_objects[0].polarity, sentiment_objects[0]"
      ],
      "metadata": {
        "id": "CIrVc9Mat6Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of polarity values and tweet text\n",
        "\n",
        "sentiment_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objects]\n",
        "\n",
        "# Print the value of the 0th row.\n",
        "\n",
        "sentiment_values[0]\n",
        "# Print all the sentiment values\n",
        "\n",
        "sentiment_values[0:99]"
      ],
      "metadata": {
        "id": "bSWWp3Zbv6qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe of each tweet against its polarity\n",
        "\n",
        "sentiment_df = pd.DataFrame(sentiment_values, columns=[\"polarity\", \"tweet\"])\n",
        "\n",
        "sentiment_df"
      ],
      "metadata": {
        "id": "HyuPsnw_woib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the polarity column as 'n'.\n",
        "\n",
        "n=sentiment_df[\"polarity\"]\n",
        "\n",
        "# Convert this column into a series, 'm'. \n",
        "\n",
        "m=pd.Series(n)\n",
        "\n",
        "m"
      ],
      "metadata": {
        "id": "oxg3s1LYw9lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables, 'pos', 'neg', 'neu'.\n",
        "\n",
        "pos=0\n",
        "neg=0\n",
        "neu=0\n",
        "\n",
        "# Create a loop to classify the tweets as Positive, Negative, or Neutral.\n",
        "# Count the number of each.\n",
        "\n",
        "for items in m:\n",
        "    if items>0:\n",
        "        print(\"Positive\")\n",
        "        pos=pos+1\n",
        "    elif items<0:\n",
        "        print(\"Negative\")\n",
        "        neg=neg+1\n",
        "    else:\n",
        "        print(\"Neutral\")\n",
        "        neu=neu+1\n",
        "        \n",
        "print(pos,neg,neu)"
      ],
      "metadata": {
        "id": "wPshaNZ4xK-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pieLabels=[\"Positive\",\"Negative\",\"Neutral\"]\n",
        "\n",
        "populationShare=[pos,neg,neu]\n",
        "\n",
        "figureObject, axesObject = plt.subplots()\n",
        "\n",
        "axesObject.pie(populationShare,labels=pieLabels,autopct='%1.2f',startangle=90)\n",
        "\n",
        "axesObject.axis('equal')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7CqO-A91xS0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of twitter users who feel a certain way about the given topic.\n",
        "\n",
        "print(\"%f percent of twitter users feel positive about %s\"%(pos,query))\n",
        "\n",
        "print(\"%f percent of twitter users feel negative about %s\"%(neg,query))\n",
        "\n",
        "print(\"%f percent of twitter users feel neutral about %s\"%(neu,query))"
      ],
      "metadata": {
        "id": "8jtPnf3Gy0Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Wordcloud from the tweets\n",
        "\n",
        "all_words = ' '.join([text for text in cleaned])\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kBGkz66vy5UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c536WIKDz8cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis (through Scraping) - Data Mining"
      ],
      "metadata": {
        "id": "02gGcsBn0B5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snscrape\n",
        "from datetime import date\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('fivethirtyeight')\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "YlUNFvGC0G96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_list = []\n",
        "maxTweets = 1000\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('Covid since:2022-01-01 until:{today}').get_items()):\n",
        "    if i>maxTweets:\n",
        "        break\n",
        "    tweets_list.append([tweet.content])\n",
        "    \n",
        "# Creating a dataframe from the tweets list above\n",
        "tweets_to_df = pd.DataFrame(tweets_list, columns=['Tweets'])\n",
        "tweets_to_df.shape"
      ],
      "metadata": {
        "id": "5GUD_7ej0sIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_to_df.head() #lists first five tweets"
      ],
      "metadata": {
        "id": "3RsebFcl1DOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clean the tweets with a function\n",
        "def cleanTweets(text):\n",
        "    text = re.sub('@[A-Za-z0-9_]+', '', text) #removes @mentions\n",
        "    text = re.sub('#','',text) #removes hastag '#' symbol\n",
        "    text = re.sub('RT[\\s]+','',text)\n",
        "    text = re.sub('https?:\\/\\/\\S+', '', text) \n",
        "    text = re.sub('\\n',' ',text)\n",
        "    return text\n",
        "tweets_to_df['cleanedTweets'] = tweets_to_df['Tweets'].apply(cleanTweets) #apply cleanTweet function to the tweet\n",
        "tweets_to_df.head() #compares original tweets with cleaned Tweets"
      ],
      "metadata": {
        "id": "Gw4pjxpt1dkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_to_df.to_csv('tweets_covid.csv') #write dataframe into csv file\n",
        "savedTweets = pd.read_csv('tweets_covid.csv',index_col=0) #reads csv file"
      ],
      "metadata": {
        "id": "iJmK93L01tqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get subjectivity and polarity of tweets with a function\n",
        "def getSubjectivity(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "#get polarity with a function\n",
        "def getPolarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "savedTweets['Subjectivity'] = savedTweets['cleanedTweets'].apply(getSubjectivity)\n",
        "savedTweets['Polarity'] = savedTweets['cleanedTweets'].apply(getPolarity)\n",
        "savedTweets.drop('Tweets', axis=1).head() #shows polarity and subjectivity of each tweet and drops the uncleaned tweets column"
      ],
      "metadata": {
        "id": "IiAUdOwr2EZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a function to check negative, neutral and positive analysis\n",
        "def getAnalysis(score):\n",
        "    if score<0:\n",
        "        return 'Negative'\n",
        "    elif score ==0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'\n",
        "    \n",
        "savedTweets['Analysis'] = savedTweets['Polarity'].apply(getAnalysis)"
      ],
      "metadata": {
        "id": "IsBk_jCQ2RJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "savedTweets['Analysis'].value_counts() #shows the counts of tweets' polarity"
      ],
      "metadata": {
        "id": "l_k_p8mE2WQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot a bar graph to show count of tweet sentiment\n",
        "fig = plt.figure(figsize=(7,5))\n",
        "color = ['green','grey','red']\n",
        "savedTweets['Analysis'].value_counts().plot(kind='bar',color = color)\n",
        "plt.title('Value count of tweet polarity')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Polarity')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WEYzorbC2ezW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pie chart to show percentage distribution of polarity\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "colors = ('green', 'grey', 'red')\n",
        "wp={'linewidth':2, 'edgecolor': 'black'}\n",
        "tags=savedTweets['Analysis'].value_counts()\n",
        "explode = (0.1,0.1,0.1)\n",
        "tags.plot(kind='pie', autopct='%1.1f%%', shadow=True, colors=colors, \n",
        "         startangle=90, wedgeprops=wp, explode=explode, label='')\n",
        "plt.title('Distribution of polarity')"
      ],
      "metadata": {
        "id": "W5CRRcjq2ljv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the polarity and subjectivity on a scatter plot\n",
        "plt.figure(figsize=(9,7))\n",
        "for i in range(0,savedTweets.shape[0]):\n",
        "    plt.scatter(savedTweets['Polarity'][i],savedTweets['Subjectivity'][i], color='blue')\n",
        "plt.title('Sentiment Analysis')\n",
        "plt.xlabel('Polarity')\n",
        "plt.ylabel('Subjectivity')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cBFwy8K42-g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a function for wordcloud\n",
        "def create_wordcloud(text):    \n",
        "    allWords = ' '.join([tweets for tweets in text])\n",
        "    wordCloud = WordCloud(background_color='white', width=800, height=500, random_state=21, max_font_size=130).generate(allWords)\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.imshow(wordCloud)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "#wordcloud for positive tweets\n",
        "posTweets = savedTweets.loc[savedTweets['Analysis']=='Positive', 'cleanedTweets']\n",
        "create_wordcloud(posTweets)\n",
        "#wordcloud for negative tweets\n",
        "negTweets = savedTweets.loc[savedTweets['Analysis']=='Negative', 'cleanedTweets']\n",
        "create_wordcloud(negTweets)"
      ],
      "metadata": {
        "id": "dAiJksLv3Hiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#break each tweet sentence into words\n",
        "sentences = []\n",
        "for word in savedTweets['cleanedTweets']:\n",
        "    sentences.append(word)\n",
        "sentences\n",
        "lines = list()\n",
        "for line in sentences:\n",
        "    words = line.split()\n",
        "    for w in words:\n",
        "        lines.append(w)\n",
        "lines[:10] #shows first 10 words in the first tweet"
      ],
      "metadata": {
        "id": "WzqqY3Qi4bXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming all the words to their root word\n",
        "stemmer = SnowballStemmer(language='english')\n",
        "stem=[]\n",
        "for word in lines:\n",
        "    stem.append(stemmer.stem(word))\n",
        "stem[:20]\n",
        "#removes stopwords (very common words in a sentence)\n",
        "stem2 = []\n",
        "for word in stem:\n",
        "    if word not in nlp.Defaults.stop_words:\n",
        "        stem2.append(word)\n",
        "#creates a new dataframe for the stem and shows the count of the most used words\n",
        "df = pd.DataFrame(stem2)\n",
        "df=df[0].value_counts()\n",
        "df #shows the new dataframe"
      ],
      "metadata": {
        "id": "omT0r5Vn4sKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plots the top 20 used words\n",
        "df = df[:20]\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(df.values, df.index, alpha=0.8)\n",
        "plt.title('Top Words Overall')\n",
        "plt.xlabel('Count of words', fontsize=12)\n",
        "plt.ylabel('Word from Tweet', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fb1QCSg747Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Random Stuff\n",
        "```\n",
        "\n",
        "# Random Stuff"
      ],
      "metadata": {
        "id": "v6dO_5sW7Esv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code allows you to get a users timeline\n",
        "# Replace user ID\n",
        "# id = '2244994945'\n",
        "# Elon Musk is 44196397\n",
        "id = '44196397'\n",
        "# https://www.codeofaninja.com/tools/find-twitter-id/#:~:text=How%20to%20use%3F&text=Put%20your%20username%20(without%20%40%20sign,appear%20in%20the%20green%20box\n",
        "\n",
        "tweets = client.get_users_tweets(id=id, tweet_fields=['context_annotations','created_at','geo'])\n",
        "\n",
        "for tweet in tweets.data:\n",
        "    print(tweet)"
      ],
      "metadata": {
        "id": "lnd36si97JnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counts for a query\n",
        "# Replace with your own search query\n",
        "query = 'covid -is:retweet'\n",
        "\n",
        "counts = client.get_recent_tweets_count(query=query, granularity='day')\n",
        "\n",
        "for count in counts.data:\n",
        "    print(count)"
      ],
      "metadata": {
        "id": "l70d8yHS7kQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Twitter IDs of the followers of a user\n",
        "\n",
        "# Replace user ID\n",
        "id = '44196397'\n",
        "\n",
        "users = client.get_users_followers(id=id, user_fields=['profile_image_url'])\n",
        "\n",
        "for user in users.data:\n",
        "    print(user.id)"
      ],
      "metadata": {
        "id": "c-TJMrFP77YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Who is Elon Musk Following\n",
        "# Replace user ID\n",
        "id = '44196397'\n",
        "\n",
        "users = client.get_users_following(id=id, user_fields=['profile_image_url'])\n",
        "\n",
        "for user in users.data:\n",
        "    print(user.id)"
      ],
      "metadata": {
        "id": "QL3r6iDx8Z_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Who like a tweet based on the tweet ID\n",
        "# Replace Tweet ID\n",
        "id = '1441054496931541004'\n",
        "\n",
        "users = client.get_liking_users(id=id, user_fields=['profile_image_url'])\n",
        "\n",
        "for user in users.data:\n",
        "    print(user)"
      ],
      "metadata": {
        "id": "sdrVgAUD8n8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Who retweet a tweet based on tweet id\n",
        "# Replace Tweet ID\n",
        "id = '1441054496931541004'\n",
        "\n",
        "users = client.get_retweeters(id=id, user_fields=['profile_image_url'])\n",
        "\n",
        "for user in users.data:\n",
        "    print(user)"
      ],
      "metadata": {
        "id": "2AxleByP8yRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give me all of the tweets that a user liked\n",
        "# Replace User ID\n",
        "id = '44196397'\n",
        "\n",
        "tweets = client.get_liked_tweets(id=id, tweet_fields=['context_annotations','created_at','geo'])\n",
        "\n",
        "for tweet in tweets.data:\n",
        "    print(tweet)"
      ],
      "metadata": {
        "id": "yA9Qeh3w8-H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look up users by twitter ID\n",
        "# Replace User IDs\n",
        "ids = ['44196397']\n",
        "\n",
        "users = client.get_users(ids=ids, user_fields=['profile_image_url'])\n",
        "\n",
        "for user in users.data:\n",
        "    print(user.profile_image_url)\n",
        "for user in users.data:\n",
        "    print(user)"
      ],
      "metadata": {
        "id": "zGkUWOJV9Lzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}